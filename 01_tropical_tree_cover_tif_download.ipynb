{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03b3464a",
   "metadata": {},
   "source": [
    "# Batch — Tropical Tree Cover (4 tiles) → Máscara ≥ 40% (10 m)\n",
    "Este notebook baixa e processa **apenas** os tiles:\n",
    "`10S_050W, 10S_060W, 20S_050W, 20S_060W`\n",
    "\n",
    "Pipeline resumido:\n",
    "1. Ler CSV/GeoJSON de subset (ou o GeoJSON original, se preferir);\n",
    "2. Baixar os **GeoTIFF F10m** de cada tile (com opção de **Bearer Token**);\n",
    "3. Aplicar **threshold de 40%** em **chunks** (sem estourar memória);\n",
    "4. Salvar **mask.tif** (uint8, tiled, LZW) e **mask.png** por tile;\n",
    "5. (Opcional) Downsample via `overview` para arquivos menores.\n",
    "\n",
    "> Observação: este ambiente de demonstração não tem internet. Execute este notebook na sua máquina (ou Colab) para baixar os rasters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11895fe2",
   "metadata": {},
   "source": [
    "## Requisitos\n",
    "```bash\n",
    "#pip install rasterio shapely pyproj requests numpy matplotlib\n",
    "\n",
    "pip install -r requirements.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7e65a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saídas em: C:\\git\\NASA\\DataRoots\\DataRoots\\outputs\\tropical_tree_cover_data\n"
     ]
    }
   ],
   "source": [
    "# ## Configurações\n",
    "import os, json\n",
    "from pathlib import Path\n",
    "\n",
    "# Arquivos de entrada (CSV e GeoJSON) foram baixados do site de forma manual\n",
    "# https://lpdaacsvc.cr.usgs.gov/appeears/products/collection/10\n",
    "# https://data.globalforestwatch.org/datasets/gfw::tropical-tree-cover/explore\n",
    "TILES_CSV = r\"outputs/Tropical_Tree_Cover.csv\"\n",
    "SUBSET_GEOJSON = r\"outputs/Tropical_Tree_Cover.geojson\"\n",
    "\n",
    "# Diretórios de saída\n",
    "OUT_DIR = Path(\"./outputs/tropical_tree_cover_data\").resolve()\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Lista explícita de tiles\n",
    "TILES_WANTED = [\"10S_050W\", \"10S_060W\", \"20S_050W\", \"20S_060W\"]\n",
    "\n",
    "# Parâmetros de processamento\n",
    "TIMEOUT = 300 # segundos para requests\n",
    "\n",
    "# Autenticação opcional (se tomar 403 nas URLs)\n",
    "USE_BEARER = False\n",
    "BEARER_TOKEN = \"COLOQUE_SEU_TOKEN_AQUI\"  # só se USE_BEARER=True\n",
    "\n",
    "print(\"Saídas em:\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a416642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiles na lista: 4\n",
      "=== 10S_050W ===\n",
      "[10S_050W] Já existe: 10S_050W_F10m.tif\n",
      "=== 10S_060W ===\n",
      "[10S_060W] Já existe: 10S_060W_F10m.tif\n",
      "=== 20S_050W ===\n",
      "[20S_050W] Baixando...\n",
      "=== 20S_060W ===\n",
      "[20S_060W] Já existe: 20S_060W_F10m.tif\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "def make_headers():\n",
    "    if USE_BEARER and BEARER_TOKEN and BEARER_TOKEN.strip():\n",
    "        return {\"Authorization\": f\"Bearer {BEARER_TOKEN.strip()}\", \"User-Agent\": \"DataRoots/TileProcessor\"}\n",
    "    return {\"User-Agent\": \"DataRoots/TileProcessor\"}\n",
    "\n",
    "def download_file(url, dest_path, chunk=1024*1024):\n",
    "    dest_path = str(dest_path)\n",
    "    headers = make_headers()\n",
    "    with requests.get(url, headers=headers, stream=True, timeout=TIMEOUT) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(dest_path, \"wb\") as f:\n",
    "            for part in r.iter_content(chunk_size=chunk):\n",
    "                if part:\n",
    "                    f.write(part)\n",
    "    return dest_path\n",
    "\n",
    "def process_tile(tile_id, url):\n",
    "    # 1) Download\n",
    "    tif_local = OUT_DIR / f\"{tile_id}_F10m.tif\"\n",
    "    if not tif_local.exists():\n",
    "        print(f\"[{tile_id}] Baixando...\")\n",
    "        try:\n",
    "            download_file(url, tif_local)\n",
    "        except Exception as e:\n",
    "            print(f\"[{tile_id}] Falha no download:\", e)\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"[{tile_id}] Já existe:\", tif_local.name)\n",
    "\n",
    "\n",
    "    return {\"tile_id\": tile_id, \"tif\": str(tif_local)}\n",
    "\n",
    "# Carrega a tabela de URLs\n",
    "tiles_df = pd.read_csv(TILES_CSV)\n",
    "tiles_df = tiles_df[tiles_df[\"tile_id\"].isin(TILES_WANTED)].copy()\n",
    "tiles_df = tiles_df[[\"tile_id\",\"F10m_download\"]].dropna().drop_duplicates()\n",
    "\n",
    "print(\"Tiles na lista:\", len(tiles_df))\n",
    "#tiles_df.head(10)\n",
    "\n",
    "results = []\n",
    "for _, row in tiles_df.iterrows():\n",
    "    tile = row[\"tile_id\"]\n",
    "    url  = row[\"F10m_download\"]\n",
    "    print(f\"=== {tile} ===\")\n",
    "    out = process_tile(tile, url)\n",
    "    if out:\n",
    "        results.append(out)\n",
    "\n",
    "res_df = pd.DataFrame(results)\n",
    "res_csv = OUT_DIR / \"batch_results.csv\"\n",
    "res_df.to_csv(res_csv, index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
